{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EHCmdaUcEAua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = ' '\n",
        "files = os.listdir('./randomsong')\n",
        "for f in files[:10]:\n",
        "  with open('./randomsong/' + f) as f:\n",
        "    text += str(f.read())\n",
        "\n",
        "\n",
        "text = text.split()\n",
        "print(text)\n",
        "words = sorted(list(set(text)))\n",
        "word_indices = dict((d,i) for i, d in enumerate(words))\n",
        "indices_word = dict((i,d) for i, d in enumerate(words))\n",
        "\n",
        "print(len(text), len(words))\n",
        "print('Vectorization...')\n",
        "\n",
        "x = np.zeros((len(text),len(words)),dtype=np.bool)\n",
        "y = np.zeros((len(text),len(words)),dtype=np.bool)\n",
        "for i in range(len(text)-1):\n",
        "  x[i,word_indices[text[i    ]]] = 1\n",
        "  y[i,word_indices[text[i+1]]] = 1\n",
        "\n",
        "  \n",
        "print('build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(words), output_dim=256))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(words)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "\n",
        "\n",
        "def sample(preds,start):    #start is not used now\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  #preds = np.log(preds)\n",
        "  #exp_preds = np.exp(preds)\n",
        "  #preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "  \n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "  start = indices_word[np.random.randint(0,len(words))]\n",
        "  sys.stdout.write(start)\n",
        "  sys.stdout.write(' ')\n",
        "  for i in range(50):\n",
        "    x_predict = np.zeros((1,len(words)),dtype=np.bool)\n",
        "    x_predict[0,word_indices[start]]=1\n",
        "    prediction = model.predict(x_predict, verbose=0)[0]\n",
        "    #start = indices_word[np.argmax(prediction)]\n",
        "    start = indices_word[sample(prediction,start)]\n",
        "    sys.stdout.write(start)\n",
        "    sys.stdout.write(' ')\n",
        "    sys.stdout.flush()\n",
        "  print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.fit(x,y,batch_size=32,epochs=10,callbacks = [print_callback])  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}