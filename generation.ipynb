{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "NVTxkmn__8RC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = ' '\n",
        "files = os.listdir('./randomsong')\n",
        "for f in files[:5]:\n",
        "  with open('./randomsong/' + f) as f:\n",
        "    text += str(f.read())\n",
        "\n",
        "\n",
        "text = text.split()\n",
        "print(text)\n",
        "words = sorted(list(set(text)))\n",
        "word_indices = dict((d,i) for i, d in enumerate(words))\n",
        "indices_word = dict((i,d) for i, d in enumerate(words))\n",
        "\n",
        "print(len(text), len(words))\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(text),len(words)),dtype=np.bool)\n",
        "y = np.zeros((len(text),len(words)),dtype=np.bool)\n",
        "for i in range(len(text)-1):\n",
        "  x[i,word_indices[text[i    ]]] = 1\n",
        "  y[i,word_indices[text[i+1]]] = 1\n",
        "  \n",
        "print('build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(words), output_dim=256))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(words)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer= 'rmsprop')\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "  start = indices_word[np.random.randint(0,len(words))]\n",
        "  sys.stdout.write(start)\n",
        "  for i in range(100):\n",
        "    x_predict = np.zeros((1,len(words)),dtype=np.bool)\n",
        "    x_predict[0,word_indices[start]]=1\n",
        "    prediction = model.predict(x_predict, verbose=0)[0]\n",
        "    start = indices_word[np.argmax(prediction)]\n",
        "    sys.stdout.write(start)\n",
        "    sys.stdout.write(' ')\n",
        "    sys.stdout.flush()\n",
        "  print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.fit(x,y,batch_size=128,epochs=10,callbacks = [print_callback])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yp7Fv9myEABg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a16c7c9-fbb0-459e-c233-5e5ce8ffec54"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdatalab\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHCmdaUcEAua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}